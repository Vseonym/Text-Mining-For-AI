{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8d1d0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentence_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "token_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "token",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "BIO_NER_tag",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "f530fdf4-a99c-400f-af3d-0ac2fe55f8ba",
       "rows": [
        [
         "0",
         "0",
         "0",
         "If",
         "O"
        ],
        [
         "1",
         "0",
         "1",
         "you're",
         "O"
        ],
        [
         "2",
         "0",
         "2",
         "visiting",
         "O"
        ],
        [
         "3",
         "0",
         "3",
         "Paris",
         "B-LOCATION"
        ],
        [
         "4",
         "0",
         "4",
         ",",
         "O"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>BIO_NER_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>you're</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>visiting</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Paris</td>\n",
       "      <td>B-LOCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id     token BIO_NER_tag\n",
       "0            0         0        If           O\n",
       "1            0         1    you're           O\n",
       "2            0         2  visiting           O\n",
       "3            0         3     Paris  B-LOCATION\n",
       "4            0         4         ,           O"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ner_test = pd.read_csv(r'NER-test.tsv', sep=\"\\t\")\n",
    "ner_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cabf0f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ner_test.groupby('sentence_id')['token'].apply(lambda tokens: ' '.join(tokens)).reset_index()\n",
    "sentences.columns = ['sentence_id', 'sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "512e2b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a36dca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_spacy = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "623c62fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9988e8cad2984f3998cad8acf7e27831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 22:45:10 INFO: Downloaded file to C:\\Users\\munzu\\stanza_resources\\resources.json\n",
      "2025-05-24 22:45:10 INFO: Downloading default packages for language: en (English) ...\n",
      "2025-05-24 22:45:11 INFO: File exists: C:\\Users\\munzu\\stanza_resources\\en\\default.zip\n",
      "2025-05-24 22:45:12 INFO: Finished downloading models and saved to C:\\Users\\munzu\\stanza_resources\n",
      "2025-05-24 22:45:12 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2fb228858540c4a7541d02dd991d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 22:45:12 INFO: Downloaded file to C:\\Users\\munzu\\stanza_resources\\resources.json\n",
      "2025-05-24 22:45:13 INFO: Loading these models for language: en (English):\n",
      "============================================\n",
      "| Processor    | Package                   |\n",
      "--------------------------------------------\n",
      "| tokenize     | combined                  |\n",
      "| mwt          | combined                  |\n",
      "| pos          | combined_charlm           |\n",
      "| lemma        | combined_nocharlm         |\n",
      "| constituency | ptb3-revised_charlm       |\n",
      "| depparse     | combined_charlm           |\n",
      "| sentiment    | sstplus_charlm            |\n",
      "| ner          | ontonotes-ww-multi_charlm |\n",
      "============================================\n",
      "\n",
      "2025-05-24 22:45:13 INFO: Using device: cpu\n",
      "2025-05-24 22:45:13 INFO: Loading: tokenize\n",
      "2025-05-24 22:45:13 INFO: Loading: mwt\n",
      "2025-05-24 22:45:13 INFO: Loading: pos\n",
      "2025-05-24 22:45:14 INFO: Loading: lemma\n",
      "2025-05-24 22:45:15 INFO: Loading: constituency\n",
      "2025-05-24 22:45:15 INFO: Loading: depparse\n",
      "2025-05-24 22:45:15 INFO: Loading: sentiment\n",
      "2025-05-24 22:45:16 INFO: Loading: ner\n",
      "2025-05-24 22:45:18 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "stanza.download(\"en\")\n",
    "nlp_stanza = stanza.Pipeline(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a26b9cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_spacy(text):\n",
    "    doc = nlp_spacy(text)\n",
    "    return [(ent.text, ent.label_) for ent in doc.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d1eac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_stanza(text):\n",
    "    doc = nlp_stanza(text)\n",
    "    return [(ent.text, ent.type) for sent in doc.sentences for ent in sent.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc9e6350",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences['spacy_entities'] = sentences['sentence'].apply(extract_entities_spacy)\n",
    "sentences['stanza_entities'] = sentences['sentence'].apply(extract_entities_stanza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed5fefcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                           sentence  \\\n",
      "0                          If you're visiting Paris , make sure to see the Louvre , as they exhibit the Mona Lisa !   \n",
      "1                                 Amazon , Google and Meta control a huge share of the technology market globally .   \n",
      "2                                             Did you hear Pharoah Sanders recorded an album with Floating Points ?   \n",
      "3                                                                Madvillainy is still my favourite MF DOOM record .   \n",
      "4   My friend Kevin just finished watching Succession , and won't stop talking about Kieran Culkin 's performance .   \n",
      "5                                                       Venus Williams has always been overshadowed by her sister .   \n",
      "6                         Since Queen Elizabeth died , King Charles has been the head of the British Royal Family .   \n",
      "7                                                                  I stayed up all night playing Dark Souls again .   \n",
      "8                                          Speaking of great movies - do you remember Once Upon a Time in America ?   \n",
      "9                                  Michael Jordan is considered one of the best players in the history of the NBA .   \n",
      "10                                              They used to call it New Amsterdam before they called it New York .   \n",
      "11                        MMA is not my favourite , but seeing John Cena is not something you get to do every day .   \n",
      "12                                         OK Computer is supposed to be one of the definitive albums of the '90s .   \n",
      "13                                                     Michael Phelps has won over 20 medals at the Olympic Games !   \n",
      "14                                 Ursula von der Leyen is the current president of the European Union Commission .   \n",
      "\n",
      "                                                                    spacy_entities  \\\n",
      "0                   [(Paris, GPE), (Louvre, PERSON), (the Mona Lisa, WORK_OF_ART)]   \n",
      "1                                      [(Amazon, ORG), (Google, ORG), (Meta, ORG)]   \n",
      "2                      [(Pharoah Sanders, PERSON), (Floating Points, WORK_OF_ART)]   \n",
      "3                                                                               []   \n",
      "4         [(Kevin, PERSON), (Succession, WORK_OF_ART), (Kieran Culkin 's, PERSON)]   \n",
      "5                                                       [(Venus Williams, PERSON)]   \n",
      "6   [(Elizabeth, PERSON), (King Charles, PERSON), (the British Royal Family, ORG)]   \n",
      "7                                                           [(Dark Souls, PERSON)]   \n",
      "8                                                                 [(America, GPE)]   \n",
      "9                          [(Michael Jordan, PERSON), (one, CARDINAL), (NBA, ORG)]   \n",
      "10                                         [(New Amsterdam, GPE), (New York, GPE)]   \n",
      "11                            [(MMA, ORG), (John Cena, PERSON), (every day, DATE)]   \n",
      "12                                          [(OK Computer, ORG), (the '90s, DATE)]   \n",
      "13                          [(Michael Phelps, PERSON), (the Olympic Games, EVENT)]   \n",
      "14  [(Ursula von der, PERSON), (Leyen, GPE), (the European Union Commission, ORG)]   \n",
      "\n",
      "                                                           stanza_entities  \n",
      "0                   [(Paris, GPE), (Louvre, FAC), (the Mona Lisa, PERSON)]  \n",
      "1                              [(Amazon, ORG), (Google, ORG), (Meta, ORG)]  \n",
      "2              [(Pharoah Sanders, PERSON), (Floating Points, WORK_OF_ART)]  \n",
      "3                                                  [(Madvillainy, PERSON)]  \n",
      "4      [(Kevin, PERSON), (Succession, PERSON), (Kieran Culkin 's, PERSON)]  \n",
      "5                                               [(Venus Williams, PERSON)]  \n",
      "6          [(Queen Elizabeth, PERSON), (Charles, PERSON), (British, NORP)]  \n",
      "7                                              [(Dark Souls, WORK_OF_ART)]  \n",
      "8                             [(Once Upon a Time in America, WORK_OF_ART)]  \n",
      "9                  [(Michael Jordan, PERSON), (one, CARDINAL), (NBA, ORG)]  \n",
      "10                                 [(New Amsterdam, GPE), (New York, GPE)]  \n",
      "11                                       [(MMA, ORG), (John Cena, PERSON)]  \n",
      "12                                     [(one, CARDINAL), (the '90s, DATE)]  \n",
      "13  [(Michael Phelps, PERSON), (20, CARDINAL), (the Olympic Games, EVENT)]  \n",
      "14  [(Ursula von der Leyen, PERSON), (the European Union Commission, ORG)]  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "print(sentences[['sentence', 'spacy_entities', 'stanza_entities']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d28e8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: If you're visiting Paris , make sure to see the Louvre , as they exhibit the Mona Lisa !\n",
      "\n",
      "spaCy entities:\n",
      "  Paris (GPE)\n",
      "  Louvre (PERSON)\n",
      "  the Mona Lisa (WORK_OF_ART)\n",
      "Stanza entities:\n",
      "  Paris (GPE)\n",
      "  Louvre (FAC)\n",
      "  the Mona Lisa (PERSON)\n",
      "------------------------------------------------------------\n",
      "Sentence: Amazon , Google and Meta control a huge share of the technology market globally .\n",
      "\n",
      "spaCy entities:\n",
      "  Amazon (ORG)\n",
      "  Google (ORG)\n",
      "  Meta (ORG)\n",
      "Stanza entities:\n",
      "  Amazon (ORG)\n",
      "  Google (ORG)\n",
      "  Meta (ORG)\n",
      "------------------------------------------------------------\n",
      "Sentence: Did you hear Pharoah Sanders recorded an album with Floating Points ?\n",
      "\n",
      "spaCy entities:\n",
      "  Pharoah Sanders (PERSON)\n",
      "  Floating Points (WORK_OF_ART)\n",
      "Stanza entities:\n",
      "  Pharoah Sanders (PERSON)\n",
      "  Floating Points (WORK_OF_ART)\n",
      "------------------------------------------------------------\n",
      "Sentence: Madvillainy is still my favourite MF DOOM record .\n",
      "\n",
      "spaCy entities:\n",
      "Stanza entities:\n",
      "  Madvillainy (PERSON)\n",
      "------------------------------------------------------------\n",
      "Sentence: My friend Kevin just finished watching Succession , and won't stop talking about Kieran Culkin 's performance .\n",
      "\n",
      "spaCy entities:\n",
      "  Kevin (PERSON)\n",
      "  Succession (WORK_OF_ART)\n",
      "  Kieran Culkin 's (PERSON)\n",
      "Stanza entities:\n",
      "  Kevin (PERSON)\n",
      "  Succession (PERSON)\n",
      "  Kieran Culkin 's (PERSON)\n",
      "------------------------------------------------------------\n",
      "Sentence: Venus Williams has always been overshadowed by her sister .\n",
      "\n",
      "spaCy entities:\n",
      "  Venus Williams (PERSON)\n",
      "Stanza entities:\n",
      "  Venus Williams (PERSON)\n",
      "------------------------------------------------------------\n",
      "Sentence: Since Queen Elizabeth died , King Charles has been the head of the British Royal Family .\n",
      "\n",
      "spaCy entities:\n",
      "  Elizabeth (PERSON)\n",
      "  King Charles (PERSON)\n",
      "  the British Royal Family (ORG)\n",
      "Stanza entities:\n",
      "  Queen Elizabeth (PERSON)\n",
      "  Charles (PERSON)\n",
      "  British (NORP)\n",
      "------------------------------------------------------------\n",
      "Sentence: I stayed up all night playing Dark Souls again .\n",
      "\n",
      "spaCy entities:\n",
      "  Dark Souls (PERSON)\n",
      "Stanza entities:\n",
      "  Dark Souls (WORK_OF_ART)\n",
      "------------------------------------------------------------\n",
      "Sentence: Speaking of great movies - do you remember Once Upon a Time in America ?\n",
      "\n",
      "spaCy entities:\n",
      "  America (GPE)\n",
      "Stanza entities:\n",
      "  Once Upon a Time in America (WORK_OF_ART)\n",
      "------------------------------------------------------------\n",
      "Sentence: Michael Jordan is considered one of the best players in the history of the NBA .\n",
      "\n",
      "spaCy entities:\n",
      "  Michael Jordan (PERSON)\n",
      "  one (CARDINAL)\n",
      "  NBA (ORG)\n",
      "Stanza entities:\n",
      "  Michael Jordan (PERSON)\n",
      "  one (CARDINAL)\n",
      "  NBA (ORG)\n",
      "------------------------------------------------------------\n",
      "Sentence: They used to call it New Amsterdam before they called it New York .\n",
      "\n",
      "spaCy entities:\n",
      "  New Amsterdam (GPE)\n",
      "  New York (GPE)\n",
      "Stanza entities:\n",
      "  New Amsterdam (GPE)\n",
      "  New York (GPE)\n",
      "------------------------------------------------------------\n",
      "Sentence: MMA is not my favourite , but seeing John Cena is not something you get to do every day .\n",
      "\n",
      "spaCy entities:\n",
      "  MMA (ORG)\n",
      "  John Cena (PERSON)\n",
      "  every day (DATE)\n",
      "Stanza entities:\n",
      "  MMA (ORG)\n",
      "  John Cena (PERSON)\n",
      "------------------------------------------------------------\n",
      "Sentence: OK Computer is supposed to be one of the definitive albums of the '90s .\n",
      "\n",
      "spaCy entities:\n",
      "  OK Computer (ORG)\n",
      "  the '90s (DATE)\n",
      "Stanza entities:\n",
      "  one (CARDINAL)\n",
      "  the '90s (DATE)\n",
      "------------------------------------------------------------\n",
      "Sentence: Michael Phelps has won over 20 medals at the Olympic Games !\n",
      "\n",
      "spaCy entities:\n",
      "  Michael Phelps (PERSON)\n",
      "  the Olympic Games (EVENT)\n",
      "Stanza entities:\n",
      "  Michael Phelps (PERSON)\n",
      "  20 (CARDINAL)\n",
      "  the Olympic Games (EVENT)\n",
      "------------------------------------------------------------\n",
      "Sentence: Ursula von der Leyen is the current president of the European Union Commission .\n",
      "\n",
      "spaCy entities:\n",
      "  Ursula von der (PERSON)\n",
      "  Leyen (GPE)\n",
      "  the European Union Commission (ORG)\n",
      "Stanza entities:\n",
      "  Ursula von der Leyen (PERSON)\n",
      "  the European Union Commission (ORG)\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for idx, row in sentences.iterrows():\n",
    "    print(f\"Sentence: {row['sentence']}\\n\")\n",
    "    print(\"spaCy entities:\")\n",
    "    for ent in row['spacy_entities']:\n",
    "        print(f\"  {ent[0]} ({ent[1]})\")\n",
    "    print(\"Stanza entities:\")\n",
    "    for ent in row['stanza_entities']:\n",
    "        print(f\"  {ent[0]} ({ent[1]})\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fefcbd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
